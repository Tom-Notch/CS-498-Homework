#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""mp4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KtyF_3P1zdt8ViWHaLBKVo766vUohRUR

#MP4

In this assignment you will be performing Semantic Segmentation. We've provided the dataset and some helper code to guide you along.

Reminders:
- When first getting your code to run do not use GPU as this will exhaust your colab resources
- When you're ready to properly test your models, make sure you are connected to a GPU runtime as this does significantly speeds up execution
    - To change your runtime do: **Runtime** --> **Change runtime type** --> under **Hardware accelerator** select **GPU**
    - Note that changing runtime resets your kernel (meaning you will need to rerun cells and local variables will be lost)
    - It also sets this new runtime as the default when you return to this notebook later
- Do not start last minute, these models do take some time to train
- Loading the data takes some time, you should only have to do this once

## Accessing the data

There are multiple ways to work with data in colab.
See this [Colab notebook](https://colab.research.google.com/notebooks/io.ipynb) or this [StackOverflow post](https://stackoverflow.com/questions/48376580/google-colab-how-to-read-data-from-my-google-drive) for more details.

Once you've mounted your drive you can see your entire drive file structure by clicking the "Files" tab on the left.

**If you wish to work locally you can ignore the first two cells, but you will still need to set the appropriate path for your dataset**
"""
# Note there are other methods to do this
from google.colab import drive

drive.mount("/content/gdrive/")

import os

if not os.path.exists("/content/gdrive/My Drive/UIUC/CS 498/Homework/Homework 4"):
    os.makedirs("/content/gdrive/My Drive/UIUC/CS 498/Homework/Homework 4")
os.chdir("/content/gdrive/My Drive/UIUC/CS 498/Homework/Homework 4")

# TODO: make sure to specify the right dataset path here
DATASET_PATH = "/content/gdrive/My Drive/UIUC/CS 498/Homework/Homework 4/data/sbd/"

# Commented out IPython magic to ensure Python compatibility.
import glob
import os
import numpy as np
import seaborn as sns
from tqdm.notebook import tqdm
import matplotlib

# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, average_precision_score
import random

from PIL import Image
import torch
from torch import nn
from torch.utils import data
import torchvision
from torchvision import models
from torchvision.transforms import ToTensor
import torchvision.transforms as transforms
import torchvision.transforms.functional as TF
import torch.nn.functional as F
import torch.optim as optim

"""## Dataset (Q1)

Here we define a class (pytorch Dataset) for accessing data. This allows us to perform transformations on the data (data augmentation) as we access it. Pytorch dataloaders take in a dataset and conventiently deal with the overhead of looping through it in batches. Creating such datasets/loaders significantly simplifies our training code later on.

**PDF: In your pdf visualize the same image (your choice which) a couple times to demonstrate your transformations**


"""


class SegmentationDataset(data.Dataset):
    """
    Data loader for the Segmentation Dataset. If data loading is a bottleneck,
    you may want to optimize this in for faster training. Possibilities include
    pre-loading all images and annotations into memory before training, so as
    to limit delays due to disk reads.
    """

    def __init__(
        self, split="train", preload=True, data_dir=DATASET_PATH, transform=False
    ):
        assert split in ["train", "val", "test"]
        self.img_dir = os.path.join(data_dir, split)
        self.classes = []
        with open(os.path.join(data_dir, "classes.txt"), "r") as f:
            for l in f:
                self.classes.append(l.rstrip())
        self.n_classes = len(self.classes)
        self.split = split
        self.data = glob.glob(self.img_dir + "/*.jpg")
        self.data = [os.path.splitext(l)[0] for l in self.data]
        self.transform = transform
        self.preload = preload
        # preload data
        if preload:
            self.images = [
                Image.open(self.data[index] + ".jpg") for index in range(len(self.data))
            ]
            self.ground_truth = [
                Image.open(self.data[index] + ".png") for index in range(len(self.data))
            ]

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        if self.preload:
            img = self.images[index]
            gt = self.ground_truth[index]
        else:
            img = Image.open(self.data[index] + ".jpg")
            gt = Image.open(self.data[index] + ".png")

        # Question 1: data augmentation
        # hint: how does transforming the image affect the ground truth?
        if self.transform:
            # Your code
            # -------------------------
            CROP_SIZE = (
                np.asarray([img.size[1], img.size[0]]) // 2
            )  # image size = 288 x 224, crop size
            FLIP_RATE = 0.5
            data = transforms.Compose(
                [
                    transforms.RandomCrop(size=CROP_SIZE),
                    transforms.RandomHorizontalFlip(p=FLIP_RATE),
                ]
            )(torch.cat([transforms.ToTensor()(img), transforms.ToTensor()(gt)]))
            img = transforms.ToPILImage()(data[:3])
            gt = transforms.ToPILImage()(data[3:])
            # -------------------------

        img = ToTensor()(img)
        gt = torch.LongTensor(np.array(gt)).unsqueeze(0)

        return img, gt


dataset = SegmentationDataset(
    split="train", preload=True, data_dir=DATASET_PATH, transform=True
)

# TODO: set the batch size, when running experiments later you should try different batch sizes
training_batch_size = 16
dataloader = data.DataLoader(
    dataset, batch_size=training_batch_size, shuffle=True, num_workers=2, drop_last=True
)

val_dataset = SegmentationDataset(
    split="val", preload=True, data_dir=DATASET_PATH, transform=False
)

val_dataloader = data.DataLoader(
    val_dataset, batch_size=16, shuffle=False, num_workers=2, drop_last=False
)


def view_image(idx):
    img = dataset[idx]
    _, axes = plt.subplots(1, 2)
    axes[0].imshow(np.swapaxes(np.swapaxes(img[0], 0, 2), 0, 1))
    axes[1].imshow(img[1][0])
    plt.show()


# You might want to look at a bunch of different images to get a feel for your data
view_image(random.randint(0, len(dataset)))

"""## Simple Baseline (Q2)

This is a trivial semantic segmentor. For each pixel location it computes the
distribution of the class label in the training set and uses that as the
prediction. In other words, if a pixel is "sky" half the time and "water" the other half in the training data, you should label it as [0.5,0,0,0,0.5,0,0,0,0].

**PDF: in your pdf report the evaluation metrics (from the next question) for this simple baseline. Also visualize the output image of simple_predict (since simple_predict outputs the same segmentation regardless of input you can just report a single image)**
"""

# train_dataset = dataset

# isTransform = train_dataset.transform
# train_dataset.transform = False
# model = np.zeros((train_dataset.n_classes, 224, 288))

# gt_classes = np.zeros_like(model)
# for i in range(train_dataset.n_classes):
#   gt_classes[i] = i

# gt_copy = np.zeros_like(model)
# for i in range(len(train_dataset)):
#   gt = train_dataset[i][1]
#   for j in range(train_dataset.n_classes):
#     gt_copy[j] = gt
#   model = np.add(model, ((gt_copy == gt_classes) * 1))
# model /= len(train_dataset)

# train_dataset.transform = isTransform

# print(model)

# dataloader = val_dataloader
# model = model.copy()

# gts, preds = [], []
# for i, batch in enumerate(tqdm(dataloader)):
#   for j in range(batch[1].shape[0]):
#     gts.append(batch[1][j].numpy())
#     preds.append(model)

# gts = np.array(gts)
# preds = np.array(preds)

# # print(gts.shape, preds.shape)


# Question 2
def simple_train(train_dataset, train_dataloader):
    # Your code
    # -------------------------
    isTransform = train_dataset.transform
    train_dataset.transform = False
    model = np.zeros((train_dataset.n_classes, 224, 288))

    gt_classes = np.zeros_like(model)
    for i in range(train_dataset.n_classes):
        gt_classes[i] = i

    gt_copy = np.zeros_like(model)
    for i in range(len(train_dataset)):
        gt = train_dataset[i][1]
        for j in range(train_dataset.n_classes):
            gt_copy[j] = gt
        model = np.add(model, ((gt_copy == gt_classes) * 1))
    model /= len(train_dataset)

    train_dataset.transform = isTransform
    # -------------------------
    return model


def simple_predict(dataloader, model):
    gts, preds = [], []
    for i, batch in enumerate(tqdm(dataloader)):
        # Your code
        # -------------------------
        for j in range(batch[1].shape[0]):
            gts.append(batch[1][j].numpy())
            preds.append(model)
        # -------------------------
    return np.array(gts), np.array(preds), list(dataset.classes)


# our "model" is class frequency, train it then make predictions for the validation set
class_freq = simple_train(dataset, dataloader)
gts, preds, classes = simple_predict(val_dataloader, class_freq)

# visualize the output segmentation prediction
plt.imshow(np.argmax(preds[0], axis=0))

"""## Evaluation Metrics (Q3)

We've implemented mean average precision. Your job is to compute the confusion matrix and IoU for a set of predictions. Namely, fill in the compute_confusion_matrix function.

The **(i,j)**th entry of a confusion matrix computes the number of observations known to be in group **i** and predicted to be in group **j**. You can use [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) as a reference and sanity check.

IoU is the intersection of the predicted and ground truth segmentation masks divided by their union. Think how these values are related to what you've already computed in the confusion matrix.
"""

# gts = gts.copy()
# preds = preds.copy()

# num_classes = preds.shape[1]

# preds_classified = []

# for i in range(preds.shape[0]):
#   preds_classified.append(np.argmax(preds[i], axis=0))

# preds_classified = np.array(preds_classified)

# # print(preds_classified.shape)
# gts = gts.reshape(preds_classified.shape)

# conf = np.zeros((num_classes, num_classes))

# # print(gts.shape, preds.shape)
# for i in range(gts.shape[1]):
#   for j in range(gts.shape[2]):
#     conf += confusion_matrix(gts[:, i, j], preds_classified[:, i, j], labels = np.arange(num_classes))

# print(conf)

# IoU = np.zeros((9))

# for i in range(num_classes):
#   IoU[i] = conf[i, i] / (np.sum(conf[i, :]) + np.sum(conf[:, i]) - conf[i, i])

# print(IoU)


def segmentation_eval(gts, preds, classes, plot_file_name):
    """
    @param    gts               numpy.ndarray   ground truth labels
    @param    preds             numpy.ndarray   predicted labels
    @param    classes           string          class names
    @param    plot_file_name    string          plot file names
    """
    ious, counts = compute_confusion_matrix(gts, preds)
    aps = compute_ap(gts, preds)
    plot_results(counts, ious, aps, classes, plot_file_name)
    for i in range(len(classes)):
        print("{:>20s}: AP: {:0.2f}, IoU: {:0.2f}".format(classes[i], aps[i], ious[i]))
    print(
        "{:>20s}: AP: {:0.2f}, IoU: {:0.2f}".format("mean", np.mean(aps), np.mean(ious))
    )
    return aps, ious


def plot_results(counts, ious, aps, classes, file_name):
    fig, ax = plt.subplots(1, 1)
    conf = counts / np.sum(counts, 1, keepdims=True)
    conf = np.concatenate(
        [conf, np.array(aps).reshape(-1, 1), np.array(ious).reshape(-1, 1)], 1
    )
    conf = conf * 100.0
    sns.heatmap(conf, annot=True, ax=ax, fmt="3.0f")
    arts = []
    # labels, title and ticks
    _ = ax.set_xlabel("Predicted labels")
    arts.append(_)
    _ = ax.set_ylabel("True labels")
    arts.append(_)
    _ = ax.set_title(
        "Confusion Matrix, mAP: {:5.1f}, mIoU: {:5.1f}".format(
            np.mean(aps) * 100.0, np.mean(ious) * 100.0
        )
    )
    arts.append(_)
    _ = ax.xaxis.set_ticklabels(classes + ["AP", "IoU"], rotation=90)
    arts.append(_)
    _ = ax.yaxis.set_ticklabels(classes, rotation=0)
    arts.append(_)
    # fig.savefig(file_name, bbox_inches='tight')
    plt.show()


def compute_ap(gts, preds):
    aps = []
    for i in range(preds.shape[1]):
        ap, prec, rec = calc_pr(gts == i, preds[:, i : i + 1, :, :])
        aps.append(ap)
    return aps


def calc_pr(gt, out, wt=None):
    gt = gt.astype(np.float64).reshape((-1, 1))
    out = out.astype(np.float64).reshape((-1, 1))
    tog = np.concatenate([gt, out], axis=1) * 1.0
    ind = np.argsort(tog[:, 1], axis=0)[::-1]
    tog = tog[ind, :]
    cumsumsortgt = np.cumsum(tog[:, 0])
    cumsumsortwt = np.cumsum(tog[:, 0] - tog[:, 0] + 1)
    prec = cumsumsortgt / cumsumsortwt
    rec = cumsumsortgt / np.sum(tog[:, 0])
    ap = voc_ap(rec, prec)
    return ap, rec, prec


def voc_ap(rec, prec):
    rec = rec.reshape((-1, 1))
    prec = prec.reshape((-1, 1))
    z = np.zeros((1, 1))
    o = np.ones((1, 1))
    mrec = np.vstack((z, rec, o))
    mpre = np.vstack((z, prec, z))

    mpre = np.maximum.accumulate(mpre[::-1])[::-1]
    I = np.where(mrec[1:] != mrec[0:-1])[0] + 1
    ap = np.sum((mrec[I] - mrec[I - 1]) * mpre[I])
    return ap


# Question 3: compute the confusion matrix and IoU metrics
# Hint: once you've computed the confusion matrix, IoU is easy
# Note: preds contains class probabilities, convert this to a class prediction
def compute_confusion_matrix(gts, preds):
    # Your code

    gts = gts.copy()
    preds = preds.copy()

    num_classes = preds.shape[1]
    IoU = np.zeros((num_classes))
    conf = np.zeros((num_classes, num_classes))

    preds_classified = []

    for i in range(preds.shape[0]):
        preds_classified.append(np.argmax(preds[i], axis=0))

    preds_classified = np.array(preds_classified)
    gts = gts.reshape(preds_classified.shape)

    for i in range(gts.shape[1]):
        for j in range(gts.shape[2]):
            conf += confusion_matrix(
                gts[:, i, j], preds_classified[:, i, j], labels=np.arange(num_classes)
            )

    for i in range(num_classes):
        IoU[i] = conf[i, i] / (np.sum(conf[i, :]) + np.sum(conf[:, i]) - conf[i, i])

    return IoU, conf


# Evaluate our trivial segmentor
aps, ious = segmentation_eval(gts, preds, classes, "cs543-simple-train.pdf")

"""## Loss function (Q4)

Implement the weighted cross entropy loss.

You may not call nn.CrossEntropy but can use it as a good reference and sanity check.

**PDF: in your pdf please describe the cross entropy loss. Also explain the purpose of using a weighted loss.**
"""

# class_freq = simple_train(dataset, dataloader)
# class_weights = []
# for i in range(9):
#     class_weights.append(1 / np.mean(class_freq[i, :, :]))
# print(class_weights)

# index = 65
# predictions = torch.from_numpy(preds.copy())
# labels = torch.from_numpy(gts.copy())
# weights = class_weights.copy() # predictions.shape == (N, num_classes, H, W) labels.shape == (N, H, W) weights == (num_calsses)

# N = predictions.shape[0]
# num_classes = len(weights)
# img_shape = predictions.shape[-2:]

# labels = labels.reshape(N, img_shape[-2], img_shape[-1])

# print("predictions.shape == ", predictions.shape, "labels.shape == ", labels.shape, "N == ", len(weights))
# loss_pytorch = nn.CrossEntropyLoss(weight=torch.tensor(weights))(predictions, labels)
# print("loss by pytorch == ", loss_pytorch)

# # print("weights == ", weights)

# # softmaxed_predictions = predictions.softmax(dim = 1)

# # loss_per_pixel = torch.zeros(labels.shape)

# # for i in range(num_classes):
# #   # print("class i ==", i, "loss = -", weights[i], "*", (labels == i)[0, 0, 0], "*", torch.log(softmaxed_predictions[:, i])[0, 0, 0], "==", - weights[i] * ((labels == i) * torch.log(softmaxed_predictions[:, i]))[0, 0, 0])
# #   loss_per_pixel += - weights[i] * ((labels == i) * torch.log(softmaxed_predictions[:, i]))

# # loss = torch.mean(loss_per_pixel)

# # print("loss == ", loss)

# predictions = torch.ones(predictions.shape)

# loss_per_pixel = torch.zeros(labels.shape)
# loss_exponential = torch.zeros(labels.shape)
# weight_per_pixel = torch.zeros(labels.shape)
# for i in range(num_classes):
#   loss_per_pixel += - predictions[:, i].reshape(labels.shape) * (labels == i)
#   loss_exponential += torch.exp(predictions[:, i].reshape(labels.shape))
#   weight_per_pixel += weights[i] * (labels == i)
# print("loss_exponential.shape == ", loss_exponential.shape)
# loss_per_pixel += torch.log(loss_exponential)
# loss_per_pixel *= weight_per_pixel

# print("loss per pixel == ", loss_per_pixel.shape, loss_per_pixel[0, 0, 0])
# loss = torch.mean(loss_per_pixel)

# print("loss == ", loss)


def cross_entropy_criterion(
    predictions, labels, weights
):  # predictions.shape == (N, num_classes, H, W) labels.shape == (N, H, W) weight.shape == (num_classes)
    # your code
    N = predictions.shape[0]
    num_classes = len(weights)
    img_shape = predictions.shape[-2:]

    loss_per_pixel = torch.zeros(labels.shape).to(device)
    loss_exponential = torch.zeros(labels.shape).to(device)
    weight_per_pixel = torch.zeros(labels.shape).to(device)

    for i in range(num_classes):
        loss_per_pixel += -predictions[:, i].reshape(labels.shape) * (labels == i)
        loss_exponential += torch.exp(predictions[:, i].reshape(labels.shape))
        weight_per_pixel += weights[i] * (labels == i)

    loss_per_pixel += torch.log(loss_exponential)
    loss_per_pixel *= weight_per_pixel

    loss = torch.mean(loss_per_pixel)
    return loss


"""## Training loop (Q5)

Fill in the training loop. We've provided validation code as well as skeleton code for training.

Keep in mind that you need to move data onto the device (GPU) as you cycle through the dataloader

While we've provided you with a skeleton to fill in, you should feel free to modify the visualization code for debugging purposes. For example you might want to print out the loss each iteration instead of once per epoch. Or you might want to compute validation accuracy metrics (like IoU) instead of just validation loss.

**PDF: in your pdf please describe why it is important to consider both validation and training losses simultaneously. When loss stops decreasing, can we change something about the training parameters to continue improving the model?**
"""


def validate_model(val_loader, model, classes, device, show_matrix=False):
    preds = np.array([]).reshape(0, 9, 224, 288)
    gts = np.array([]).reshape(0, 1, 224, 288)
    with torch.no_grad():
        for data in val_loader:
            inputs, labels = data
            inputs = inputs.to(device)

            outputs = model(inputs).cpu().numpy()
            preds = np.concatenate([preds, outputs], axis=0)
            gts = np.concatenate([gts, labels.numpy()], axis=0)

            print(
                "Validating...{}\r".format(100.0 * len(preds) / len(val_loader)), end=""
            )

    if show_matrix:
        aps, ious = segmentation_eval(gts, preds, classes, "cs543-simple-val_3.pdf")
    else:
        ious, counts = compute_confusion_matrix(gts, preds)
        aps = compute_ap(gts, preds)
        for i in range(len(classes)):
            print(
                "{:>20s}: AP: {:0.2f}, IoU: {:0.2f}".format(classes[i], aps[i], ious[i])
            )
        print(
            "{:>20s}: AP: {:0.2f}, IoU: {:0.2f}".format(
                "mean", np.mean(aps), np.mean(ious)
            )
        )

    return preds, gts


# Your goal is to complete this function
def train(model, optimizer, criterion, trainloader, device, valloader=None, epochs=15):
    train_loss_over_epochs = []
    val_loss_over_epochs = []
    plt.ioff()
    fig = plt.figure()
    for epoch in tqdm(range(epochs), total=epochs):
        # running loss is the **average** loss for each item in the dataset during this epoch
        running_loss = 0.0
        losses = []
        for i, data in enumerate(trainloader, 0):
            # Your code
            # -------------------------
            N = data[0].shape[0]
            num_classes = 9
            img_shape = data[0].shape[-2:]

            img = torch.tensor(data[0]).reshape(N, 3, *img_shape).to(device)

            labels = torch.tensor(data[1]).reshape(N, *img_shape).to(device)

            predictions = model(img)
            loss = criterion(predictions.reshape((N, num_classes, *img_shape)), labels)
            losses.append(loss)

            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            # with torch.no_grad():
            #   _, axes = plt.subplots(1,3) # visualize result on the run
            #   original_img = img[-1].clone().to("cpu")
            #   original_img = original_img.swapaxes(0, 1).swapaxes(1, 2)
            #   axes[0].imshow(original_img)
            #   axes[1].imshow(labels[-1].to("cpu"))
            #   axes[2].imshow(torch.argmax(predictions[-1], axis=0).to("cpu"))
            #   plt.show()

        running_loss = torch.mean(torch.tensor(losses))
        # -------------------------

        train_loss_over_epochs.append(running_loss)
        # Note: it can be more readable to overwrite the previous line - end="\r"
        print("Epoch: {}, training loss: {:.3f}".format(epoch + 1, running_loss))

        # If you pass in a validation dataloader then compute the validation loss
        if not valloader is None:
            val_loss = 0.0
            with torch.no_grad():
                losses = []
                for data in valloader:
                    # Your code
                    # -------------------------
                    N = data[0].shape[0]
                    num_classes = 9
                    img_shape = data[0].shape[-2:]

                    img = torch.tensor(data[0]).reshape(N, 3, *img_shape).to(device)

                    labels = torch.tensor(data[1]).reshape(N, *img_shape).to(device)

                    predictions = model(img)
                    loss = criterion(
                        predictions.reshape((N, num_classes, *img_shape)), labels
                    )
                    losses.append(loss)

                    _, axes = plt.subplots(1, 3)  # visualize result on the run
                    original_img = img[-1].clone().to("cpu")
                    original_img = original_img.swapaxes(0, 1).swapaxes(1, 2)
                    axes[0].imshow(original_img)
                    axes[1].imshow(labels[-1].to("cpu"))
                    axes[2].imshow(torch.argmax(predictions[-1], axis=0).to("cpu"))
                    plt.show()

                val_loss = torch.mean(torch.tensor(losses))
                # -------------------------
            val_loss_over_epochs.append(val_loss)
            print("Epoch: {}, validation loss: {:.3f}".format(epoch + 1, val_loss))

    plt.subplot(2, 1, 1)
    plt.ylabel("Loss")
    plt.plot(np.arange(epochs), train_loss_over_epochs, color="red", label="train")
    if not valloader is None:
        plt.plot(np.arange(epochs), val_loss_over_epochs, color="blue", label="val")
    plt.title("Loss per Epoch")
    plt.xticks(np.arange(epochs, dtype=int))
    plt.grid(True)
    plt.legend()
    plt.show()
    return model


"""## Model definitions (Q6)

Now create your models. Create one basic Convolutional architecture and one U-Net architecture.

We provide some helpful methods below to compute the size of your next convolutional layer (you can find these formula at TODO).

Some things to keep in mind:
- your basic layer is nn.Conv2D, read its documentation
- for UNet you will also need nn.ConvTranspose2D and Pooling layers
- nn.BatchNorm2d is incredibly helpful between layers
- you can stick to ReLU activations, but are welcome to report results with other activation functions
- the model output should be class probabilities

**PDF: in your pdf please describe your final model architectures. Report the training plots and final accuracy metrics on the validation set for each model. What batch size, learning rate, optimizer did you find works best. Perform a small ablation study: what is the effect of batchnorm on training speed and accuracy? Visualize a few images and their predicted segmentation masks by your UNet model.**
"""


def conv_out_size(inp_size, kernel_size, dilation=1, padding=0, stride=1):
    return ((inp_size + 2 * padding - dilation * (kernel_size - 1) - 1) // stride) + 1


def conv_trans_out_size(
    inp_size, kernel_size, dilation=1, padding=0, stride=1, out_padding=0
):
    return (
        (inp_size - 1) * stride
        - 2 * padding
        + dilation * (kernel_size - 1)
        + out_padding
        + 1
    )


class BaseConv(nn.Module):
    def __init__(self):
        super(BaseConv, self).__init__()

        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),
        )

        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),
        )

        self.layer4 = nn.Sequential(
            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),
        )

        self.layer5 = nn.Sequential(
            nn.Conv2d(512, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(1024, 1024, 2, stride=2),
        )  # bottom layer

        self.layer6 = nn.Sequential(
            nn.Conv2d(1024, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 512, 2, stride=2),
        )

        self.layer7 = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 256, 2, stride=2),
        )

        self.layer8 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 128, 2, stride=2),
        )

        self.layer9 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 9, 1),
        )

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.layer5(x)
        x = self.layer6(x)
        x = self.layer7(x)
        x = self.layer8(x)
        x = self.layer9(x)

        return x


class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        self.layer1_pool = nn.MaxPool2d(2, stride=2)

        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        self.layer2_pool = nn.MaxPool2d(2, stride=2)

        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        self.layer3_pool = nn.MaxPool2d(2, stride=2)

        self.layer4 = nn.Sequential(
            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
        )
        self.layer4_pool = nn.MaxPool2d(2, stride=2)

        self.layer5 = nn.Sequential(
            nn.Conv2d(512, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(1024, 512, 2, stride=2),
        )  # bottom layer

        self.layer6 = nn.Sequential(
            nn.Conv2d(1024, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, 2, stride=2),
        )

        self.layer7 = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 2, stride=2),
        )

        self.layer8 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 2, stride=2),
        )

        self.layer9 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 9, 1),
        )

    def forward(self, x):
        x1 = self.layer1(x)
        x = self.layer1_pool(x1)

        x2 = self.layer2(x)
        x = self.layer2_pool(x2)

        x3 = self.layer3(x)
        x = self.layer3_pool(x3)

        x4 = self.layer4(x)
        x = self.layer4_pool(x4)

        x = self.layer5(x)

        x = self.layer6(torch.cat((x4, x), 1))

        x = self.layer7(torch.cat((x3, x), 1))

        x = self.layer8(torch.cat((x2, x), 1))

        x = self.layer9(torch.cat((x1, x), 1))

        return x


"""### Now we can finally train our models..."""

# if runtime has GPU use GPU
if torch.cuda.is_available():
    device = torch.device("cuda:0")
else:
    device = torch.device("cpu")
print("Using device:", device)

# For the weighted cross entropy loss we can compute class weights using our simple baseline
class_freq = simple_train(dataset, dataloader)
class_weights = []
for i in range(9):
    class_weights.append(1 / np.mean(class_freq[i, :, :]))
print(class_weights)

"""### Basic convolutional model training"""

dataset = SegmentationDataset(
    split="train", preload=True, data_dir=DATASET_PATH, transform=True
)

training_batch_size = 64
dataloader = data.DataLoader(
    dataset, batch_size=training_batch_size, shuffle=True, num_workers=2, drop_last=True
)


val_dataset = SegmentationDataset(
    split="val", preload=True, data_dir=DATASET_PATH, transform=False
)

val_dataloader = data.DataLoader(
    val_dataset, batch_size=16, shuffle=False, num_workers=2, drop_last=False
)

# First make the model and put it on the device
base_model = BaseConv().to(device)

# Now define our loss criterion as cross entropy based on your previous code
# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))
criterion = lambda y_pred, y_true: cross_entropy_criterion(
    y_pred, y_true, torch.tensor(class_weights, dtype=torch.float).to(device)
)

# Now make our optimizer for this model
# TODO: pick an optimizer from torch.optim and set the learning rate
lr = 0.0001
optimizer = optim.Adam(base_model.parameters(), lr=lr)

# TODO: how many epochs to train for?
epochs = 128

# Now train and validate
# Consider putting this code into a loop,
# thus alternating between training for some number of epochs and validating
base_model = train(
    base_model.train(),
    optimizer,
    criterion,
    dataloader,
    device,
    valloader=val_dataloader,
    epochs=epochs,
)

preds, gts = validate_model(
    val_dataloader, base_model.eval(), list(dataset.classes), device, show_matrix=True
)

"""#### UNet model training"""

model_unet = UNet().to(device)

epochs = 128

# TODO: fill in this code as you did above for the basic convolutional model
lr = 0.0001
optimizer_UNet = optim.Adam(model_unet.parameters(), lr=lr)

model_unet = train(
    model_unet.train(),
    optimizer_UNet,
    criterion,
    dataloader,
    device,
    valloader=val_dataloader,
    epochs=epochs,
)

preds_unet, gts_unet = validate_model(
    val_dataloader, model_unet.eval(), list(dataset.classes), device, show_matrix=True
)

"""Make sure to report the results for both models.

## Working off a pretrained model (Q7)

Finally, you will now modify a pretrained model (resnet18) and use it as an initialization for training. You should be able to get better results with this model than before.

You can finetune (meaning backpropagate through the resnet layers) or not. You can finetune just some layers and not others. It's up to you.

**PDF: in your pdf report the final accuracy of your model based on a pretrained model. Describe how you used the pretrained model, which features did you extract and why?**
"""

pretrained_resnet = models.resnet18(pretrained=True)

# h = 224

# print(h)
# h = conv_out_size(h, 7, dilation = 1, padding = 3, stride = 2)
# print(h)
# h = conv_out_size(h, 3, dilation = 1, padding = 1, stride = 2)
# print(h)

# h = conv_out_size(h, 3, dilation = 1, padding = 1, stride = 1) # layer 1
# print(h)

# h = conv_out_size(h, 3, dilation = 1, padding = 1, stride = 2) # layer 2
# print(h)

# h = conv_out_size(h, 1, dilation = 1, padding = 0, stride = 2)
# print(h)

# for param in pretrained_resnet.parameters():
#   print(type(param), param.shape)

# print(pretrained_resnet.forward)

# resnet_modules = [module for module in pretrained_resnet.modules() if not isinstance(module, nn.Sequential)]
# for i, module in enumerate(resnet_modules):
#   print(i, resnet_modules[i])

# resnet_features = nn.Sequential(*list(pretrained_resnet.children()))
# print("number of layers ==", len(resnet_features))
# for i, feature in enumerate(resnet_features):
#   print(i, feature)


class ResnetBasedModel(nn.Module):
    def __init__(self, pretrained_resnet, num_layers_to_remove=0):
        super(ResnetBasedModel, self).__init__()
        # You can, for example, extract the first N layers of the model like this:
        # self.resnet_features = nn.Sequential(*list(pretrained_resnet.children())[:N])
        self.layer1_UNet = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        self.layer1_UNet_pool = nn.MaxPool2d(2, stride=2)

        self.layer2_ResNet = nn.Sequential(
            *list(pretrained_resnet.children())[:3]
        )  # channel: 3 => 64
        self.layer2_UNet = nn.Sequential(
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        self.layer2_UNet_pool = nn.MaxPool2d(2, stride=2)

        self.layer3_ResNet = nn.Sequential(
            *list(pretrained_resnet.children())[3:5]
        )  # channel: 64 => 64
        self.layer3_UNet = nn.Sequential(
            nn.Conv2d(192, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        self.layer3_UNet_pool = nn.MaxPool2d(2, stride=2)

        self.layer4_ResNet = nn.Sequential(
            *list(pretrained_resnet.children())[5:6]
        )  # channel: 64 => 128
        self.layer4_UNet = nn.Sequential(
            nn.Conv2d(384, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
        )
        self.layer4_UNet_pool = nn.MaxPool2d(2, stride=2)

        self.layer5_ResNet = nn.Sequential(
            *list(pretrained_resnet.children())[6:7]
        )  # channel: 128 => 256
        self.layer5_UNet = nn.Sequential(
            nn.Conv2d(768, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(1024, 512, 2, stride=2),
        )

        self.layer6_UNet = nn.Sequential(
            nn.Conv2d(1024, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, 2, stride=2),
        )

        self.layer7_UNet = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, 2, stride=2),
        )

        self.layer8_UNet = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, 2, stride=2),
        )

        self.layer9_UNet = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 9, 1),
        )

    def forward(self, x):
        x1 = self.layer1_UNet(x)

        res_x = self.layer2_ResNet(x)
        x = self.layer1_UNet_pool(x1)
        x2 = self.layer2_UNet(torch.cat((res_x, x), 1))

        res_x = self.layer3_ResNet(res_x)
        x = self.layer2_UNet_pool(x2)
        x3 = self.layer3_UNet(torch.cat((res_x, x), 1))

        res_x = self.layer4_ResNet(res_x)
        x = self.layer3_UNet_pool(x3)
        x4 = self.layer4_UNet(torch.cat((res_x, x), 1))

        res_x = self.layer5_ResNet(res_x)
        x = self.layer4_UNet_pool(x4)
        x = self.layer5_UNet(torch.cat((res_x, x), 1))

        x = self.layer6_UNet(torch.cat((x4, x), 1))

        x = self.layer7_UNet(torch.cat((x3, x), 1))

        x = self.layer8_UNet(torch.cat((x2, x), 1))

        x = self.layer9_UNet(torch.cat((x1, x), 1))

        return x


def freeze_parameters(model):
    for param in model.parameters():
        param.requires_grad = False


def unfreeze_parameters(model):
    for param in model.parameters():
        param.requires_grad = True


resnet_based_model = ResnetBasedModel(pretrained_resnet).to(device)

# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))
criterion = lambda y_pred, y_true: cross_entropy_criterion(
    y_pred, y_true, torch.tensor(class_weights, dtype=torch.float).to(device)
)

freeze_parameters(pretrained_resnet)
optimizer_resunet = optim.Adam(resnet_based_model.parameters(), lr=0.001)
resnet_based_model = train(
    resnet_based_model.train(),
    optimizer_resunet,
    criterion,
    dataloader,
    device,
    valloader=val_dataloader,
    epochs=64,
)

unfreeze_parameters(pretrained_resnet)
optimizer_resunet = optim.Adam(resnet_based_model.parameters(), lr=0.0001)
resnet_based_model = train(
    resnet_based_model.train(),
    optimizer_resunet,
    criterion,
    dataloader,
    device,
    valloader=val_dataloader,
    epochs=32,
)

preds, gts = validate_model(
    val_dataloader,
    resnet_based_model.eval(),
    list(dataset.classes),
    device,
    show_matrix=True,
)

"""# Test set

Finally we can check evaluation on test set....

**PDF: in your pdf report the results of your best model (this should be based on a pretrained model) on the test dataset.**
"""

test_dataset = SegmentationDataset(
    split="test", preload=True, data_dir=DATASET_PATH, transform=False
)
test_dataloader = data.DataLoader(
    test_dataset, batch_size=16, shuffle=False, num_workers=2, drop_last=False
)

preds, gts = validate_model(
    test_dataloader, base_model.eval(), list(dataset.classes), device, show_matrix=True
)

preds, gts = validate_model(
    test_dataloader, model_unet.eval(), list(dataset.classes), device, show_matrix=True
)

preds, gts = validate_model(
    test_dataloader,
    resnet_based_model.eval(),
    list(dataset.classes),
    device,
    show_matrix=True,
)

# model = resnet_based_model.to('cpu')
# dataset = dataset


# isTransform = dataset.transform
# dataset.transform = False
# num_classes = len(dataset.classes)
# N = len(dataset)

# for data in dataset:
#   _, axes = plt.subplots(1,3) # visualize result on the run
#   original_img = data[0].clone()
#   print(type(original_img), original_img.shape)
#   img_shape = original_img.shape[-2:]

#   prediction = model(original_img.reshape(1, *original_img.shape))
#   original_img = original_img.swapaxes(0, 1).swapaxes(1, 2)
#   axes[0].imshow(original_img)
#   axes[1].imshow(data[1].reshape(img_shape))
#   axes[2].imshow(torch.argmax(prediction.reshape(num_classes, *img_shape), axis=0))
#   plt.show()

# dataset.transform = isTransform
